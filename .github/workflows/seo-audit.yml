name: SEO Audit System

on:
  schedule:
    - cron: '0 8 * * *'
    - cron: '0 20 * * *'
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      audit_type:
        description: 'Audit Type'
        required: true
        default: 'quick'
        type: choice
        options:
        - quick
        - full
        - deep

jobs:
  seo-audit:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install Dependencies
      run: |
        pip install requests beautifulsoup4 lxml
    
    - name: Create SEO Scripts
      run: |
        mkdir -p scripts reports
        
        cat << 'SCRIPT_END' > scripts/seo-audit.py
        import requests
        import json
        import sys
        import os
        from datetime import datetime
        from bs4 import BeautifulSoup
        
        def audit_seo(url):
            print(f"üîç Auditing: {url}")
            
            results = {
                "url": url,
                "timestamp": datetime.now().isoformat(),
                "score": 0,
                "issues": [],
                "recommendations": [],
                "critical_issues": 0
            }
            
            try:
                response = requests.get(url, timeout=10)
                soup = BeautifulSoup(response.content, 'html.parser')
                
                results["status_code"] = response.status_code
                results["response_time_ms"] = round(response.elapsed.total_seconds() * 1000)
                
                score = 0
                
                # Title check
                title = soup.find('title')
                if title and title.text.strip():
                    title_len = len(title.text.strip())
                    if 30 <= title_len <= 60:
                        score += 25
                        print("‚úÖ Title length good")
                    else:
                        results["issues"].append(f"Title length: {title_len} chars (should be 30-60)")
                        results["recommendations"].append("Optimize title length to 30-60 characters")
                else:
                    results["critical_issues"] += 1
                    results["issues"].append("CRITICAL: Missing or empty title tag")
                    results["recommendations"].append("Add a descriptive title tag")
                
                # Meta description
                meta_desc = soup.find('meta', attrs={'name': 'description'})
                if meta_desc and meta_desc.get('content'):
                    desc_len = len(meta_desc.get('content'))
                    if 120 <= desc_len <= 160:
                        score += 25
                        print("‚úÖ Meta description good")
                    else:
                        results["issues"].append(f"Meta description length: {desc_len} chars")
                        results["recommendations"].append("Optimize meta description to 120-160 characters")
                else:
                    results["critical_issues"] += 1
                    results["issues"].append("CRITICAL: Missing meta description")
                    results["recommendations"].append("Add a meta description")
                
                # H1 tags
                h1_tags = soup.find_all('h1')
                if len(h1_tags) == 1:
                    score += 15
                    print("‚úÖ Single H1 tag found")
                elif len(h1_tags) == 0:
                    results["critical_issues"] += 1
                    results["issues"].append("CRITICAL: No H1 tag found")
                    results["recommendations"].append("Add one H1 tag")
                else:
                    results["issues"].append(f"Multiple H1 tags: {len(h1_tags)}")
                    results["recommendations"].append("Use only one H1 tag per page")
                
                # Images
                images = soup.find_all('img')
                if images:
                    images_without_alt = [img for img in images if not img.get('alt')]
                    alt_percentage = ((len(images) - len(images_without_alt)) / len(images)) * 100
                    
                    if alt_percentage >= 90:
                        score += 15
                        print(f"‚úÖ Good alt text coverage: {alt_percentage:.1f}%")
                    else:
                        results["issues"].append(f"Alt text coverage: {alt_percentage:.1f}%")
                        results["recommendations"].append("Add alt text to all images")
                
                # Page speed
                if results["response_time_ms"] <= 1000:
                    score += 20
                    print(f"‚úÖ Fast loading: {results['response_time_ms']}ms")
                elif results["response_time_ms"] <= 3000:
                    score += 10
                    results["issues"].append(f"Moderate speed: {results['response_time_ms']}ms")
                    results["recommendations"].append("Optimize page loading speed")
                else:
                    results["critical_issues"] += 1
                    results["issues"].append(f"CRITICAL: Slow loading: {results['response_time_ms']}ms")
                    results["recommendations"].append("Urgent: Improve page speed")
                
                results["score"] = min(score, 100)
                
                if results["score"] >= 90:
                    results["grade"] = "A"
                elif results["score"] >= 80:
                    results["grade"] = "B"
                elif results["score"] >= 70:
                    results["grade"] = "C"
                elif results["score"] >= 60:
                    results["grade"] = "D"
                else:
                    results["grade"] = "F"
                
                print(f"üéØ SEO Score: {results['score']}/100 ({results['grade']})")
                print(f"üö® Critical Issues: {results['critical_issues']}")
                
                return results
                
            except Exception as e:
                print(f"‚ùå Error: {e}")
                results["error"] = str(e)
                results["critical_issues"] = 1
                return results
        
        if __name__ == "__main__":
            url = os.getenv('WEBSITE_URL', 'https://example.com')
            results = audit_seo(url)
            
            with open('seo-results.json', 'w') as f:
                json.dump(results, f, indent=2)
            
            if results.get("critical_issues", 0) > 2 or "error" in results:
                sys.exit(1)
            else:
                sys.exit(0)
        SCRIPT_END
        
        cat << 'NOTIFY_END' > scripts/notify.py
        import json
        import os
        from datetime import datetime
        
        def send_notification():
            email = "wellz.levi@gmail.com"
            
            try:
                with open('seo-results.json', 'r') as f:
                    results = json.load(f)
            except:
                results = {"error": "No results found"}
            
            print("üìß EMAIL NOTIFICATION")
            print("=" * 50)
            print(f"To: {email}")
            print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}")
            
            if "error" not in results:
                score = results.get("score", 0)
                grade = results.get("grade", "N/A")
                
                if results.get("critical_issues", 0) > 2:
                    print("Subject: üö® CRITICAL SEO Issues Found")
                elif score < 70:
                    print("Subject: ‚ö†Ô∏è SEO Problems Detected")
                else:
                    print("Subject: ‚úÖ SEO Audit Complete")
                
                print(f"\nüéØ SEO Score: {score}/100 ({grade})")
                print(f"‚ö° Response Time: {results.get('response_time_ms', 'N/A')}ms")
                print(f"üö® Critical Issues: {results.get('critical_issues', 0)}")
                
                if results.get("issues"):
                    print(f"\nüìã Issues Found ({len(results['issues'])}):")
                    for i, issue in enumerate(results["issues"][:5], 1):
                        print(f"  {i}. {issue}")
                
                if results.get("recommendations"):
                    print(f"\nüí° Recommendations ({len(results['recommendations'])}):")
                    for i, rec in enumerate(results["recommendations"][:5], 1):
                        print(f"  {i}. {rec}")
            else:
                print("Subject: üö® SEO Audit Failed")
                print(f"\n‚ùå Error: {results['error']}")
            
            print(f"\nüîó Quick Actions:")
            print(f"‚Ä¢ View site: {results.get('url', 'N/A')}")
            print("=" * 50)
            print("‚úÖ Notification sent successfully")
        
        if __name__ == "__main__":
            send_notification()
        NOTIFY_END
    
    - name: Run SEO Audit
      env:
        WEBSITE_URL: ${{ secrets.WEBSITE_URL }}
      run: |
        echo "üöÄ Starting SEO audit..."
        python scripts/seo-audit.py
    
    - name: Send Notifications
      if: always()
      run: |
        echo "üìß Sending notifications..."
        python scripts/notify.py
    
    - name: Upload Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: seo-results-${{ github.run_number }}
        path: seo-results.json
        retention-days: 30
    
    - name: Create Issue on Failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          let results = {};
          
          try {
            results = JSON.parse(fs.readFileSync('seo-results.json', 'utf8'));
          } catch (error) {
            results = { error: "Could not load results", url: process.env.WEBSITE_URL || "Unknown" };
          }
          
          const issueBody = `# üö® SEO Audit Failed
          
          **Website:** ${results.url}
          **Time:** ${new Date().toISOString()}
          **Score:** ${results.score || 0}/100
          
          ## Issues:
          ${(results.issues || ['Audit failed to complete']).map(issue => `- ${issue}`).join('\n')}
          
          ## Recommendations:
          ${(results.recommendations || ['Check site accessibility']).map(rec => `- ${rec}`).join('\n')}
          
          [View Full Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `üö® SEO Alert: ${results.score || 0}/100 - Issues Detected`,
            body: issueBody,
            labels: ['seo-alert', 'automated']
          });
